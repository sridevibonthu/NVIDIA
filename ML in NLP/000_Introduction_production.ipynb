{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Transformer-Based Natural Language Processing Applications\n",
    "### Part 3: Production Deployment\n",
    "\n",
    "The goal of this lab is to deploy an example NLP model to a production inference server. \n",
    "\n",
    "<img style=\"float: right;\" src=\"images/triton-diagram.jpg\" width=500>\n",
    "\n",
    "For our project, we'll use NVIDIA Triton Inference Server.  The \"results\" you'll get from production inference are the same as when using the model's framework directly, but using Triton has additional benefits:\n",
    "* Concurrent model execution (can run multiple models simultaneously)\n",
    "* Dynamic batching (better throughput)\n",
    "* Model hot replacement (can update while server is running)\n",
    "* Docker container available (portable)\n",
    "* Multiple framework support (TensorRT, TensorFlow, PyTorch, ONNX)\n",
    "\n",
    "## Table of Contents\n",
    "1. [Exporting the Model](010_ExportingTheModel.ipynb)<br/>\n",
    "    You'll learn how to:\n",
    "    - Convert a model trained in PyTorch into a server-efficient format<br/>\n",
    "    - Apply reduced precision and TensorRT model optimizations <br/>\n",
    "2. [Hosting the Model](020_HostingTheModel.ipynb)<br/>\n",
    "    You'll learn how to:\n",
    "    - Deploy the model to production using an NVIDIA Triton Inference Server<br/>\n",
    "    - Control some of the basic features of NVIDIA Triton via the model configuration. <br/>\n",
    "    - Evaluate the impact of export format and configuration choices on performance and cost<br/>\n",
    "3. [Server Performance](030_ServerPerformance.ipynb)<br/>\n",
    "    You'll learn how to:\n",
    "    - Evaluate the impact different Triton configuration options on serving performance<br/>\n",
    "    - Monitor the performance of inference in production <br/>\n",
    "4. [Using the Model](040_UsingTheModel.ipynb)<br/>\n",
    "    You'll learn how to:\n",
    "    - Build a simple application that can take advantage of the API exposed by Triton<br/>\n",
    "    - Discuss the options for more complex application and model pipeline deployments<br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JupyterLab\n",
    "For this hands-on lab, we use [JupyterLab](https://jupyterlab.readthedocs.io/en/stable/) to manage our environment.  The [JupyterLab Interface](https://jupyterlab.readthedocs.io/en/stable/user/interface.html) is a dashboard that provides access to interactive iPython notebooks, as well as the folder structure of our environment and a terminal window into the Ubuntu operating system. The first view you'll see includes a **menu bar** at the top, a **file browser** in the **left sidebar**, and a **main work area** that is initially open to the \"Launcher\" page. \n",
    "\n",
    "<img src=\"images/jl_launcher.png\">\n",
    "\n",
    "The file browser can be navigated just like any other file explorer. A double click on any of the items will open a new tab with its content.\n",
    "\n",
    "The main work area includes tabbed views of open files that can be closed, moved, and edited as needed. \n",
    "\n",
    "The notebooks, including this one, consist of a series of content and code **cells**.  To execute code in a code cell, press `Shift+Enter` or the \"Run\" button in the menu bar above, while a cell is highlighted. Sometimes, a content cell will get switched to editing mode. Pressing `Shift+Enter` will switch it back to a readable form.\n",
    "\n",
    "Try executing the simple print statement in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is just a simple print statement\n"
     ]
    }
   ],
   "source": [
    "# Highlight this cell and click [Shift+Enter] to execute\n",
    "print('This is just a simple print statement')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
